#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass report
\begin_preamble
\usepackage[bottom]{footmisc}
\usepackage{fancyhdr}
\pagestyle{fancy}
\usepackage{minitoc}
\usepackage{pgfplots}
\usepackage{lmodern}

\usepackage{titletoc}% http://ctan.org/pkg/titletoc
\titlecontents{chapter}% <section-type>
  [0pt]% <left>
  {\bfseries}% <above-code>
  {\chaptername\ \thecontentslabel:\quad}% <numbered-entry-format>
  {}% <numberless-entry-format>
  {\hfill\contentspage}% <filler-page-format>

\fancyhead[R,C]{}
\fancyhead[L]{\footnotesize\leftmark}
\renewcommand{\headrulewidth}{1pt}
\fancyfoot[L,C]{}
\fancyfoot[R]{\thepage}
\renewcommand{\footrulewidth}{0pt}

\oddsidemargin = 18pt
\topmargin = 0pt
\headheight = 22pt
\headsep = 25pt
\textheight = 609pt
\textwidth = 424pt
\marginparsep = 11pt
\marginparwidth = 54pt
\footskip = 50pt
\marginparpush = 54pt
\hoffset = 0pt
\voffset = 0pt
\end_preamble
\use_default_options true
\begin_modules
theorems-bytype
\end_modules
\maintain_unincluded_children false
\language french
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement h
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\headheight 3cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style swiss
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\bullet 1 0 8 -1
\bullet 2 0 9 -1
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
État de l'art
\end_layout

\begin_layout Quotation
\align right

\emph on
\begin_inset Quotes cld
\end_inset

...ce que nous voulons, c'est une machine qui peut apprendre de l'expérience
\begin_inset Quotes crd
\end_inset

.
 A.
 Turing.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
minitoc
\end_layout

\begin_layout Plain Layout


\backslash
thispagestyle{empty}
\end_layout

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Introduction
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{section}{Introduction}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Dans le but d’effectuer un comportement a cette lampe robotisée, nous avons
 besoins de passer par trois étapes dans le traitement de l’image qui a
 été capturée par la webcam de la lampe.
 Ces trois étapes viennent séquentiellement l’une après l’autre dans l’ordre
 suivant : Détection de l’image voire un flux d’image afin d’en extraire
 une ou plusieurs régions d’intérêt, ensuite l’extractions des points de
 saillances suivies des opérations de normalisation pour former des vecteurs
 descripteurs, et à la fin faire de la classification des caractéristiques
 pour ces points extraits ce qu’on appelle le Clustering.
\end_layout

\begin_layout Section
Détection de visage
\end_layout

\begin_layout Standard
La détection de visage est un type d’application classé dans la technologie
 de vision par ordinateur.
 C’est le processus aux cours duquel des algorithmes sont développés et
 formés pour localiser correctement les visages ou les objets.
 Celles-ci peuvent être en tems réel à partir d’une caméra vidéo.
 Afin de détecter la position des visages dans les images de sorte à obtenir
 une région d’intérêt sur laquelle l’extraction des vecteurs de caractéristiques
 pourra être accomplie il y a bien de nombreuses méthodes, dans ce qui suit
 nous allons présenter les méthodes les plus utilisées dans la détection.
\end_layout

\begin_layout Subsection
Haar cascade
\end_layout

\begin_layout Standard
Les cascades de Haar est une méthode utilisée pour la détection d’objet
 de classificateurs en cascade basés sur les fonctionnalités Haar, c’est
 une méthode efficace de détection d’objets proposée par Paul Viola et Michel
 Jones en 2001.
 Il s’agit d’une approche basée sur l’apprentissage automatique.
\end_layout

\begin_layout Standard
La fonction cascade est formée à partir de nombreuses images positives et
 négatives.
 Il est par la suite utilisé pour détecter des objets dans d’autres images.
 Cette méthode travaille avec la détection de visage.
 Initialement, l’algorithme nécessite beaucoup d’images positives (image
 de visage) et d’images négatives (images sans visages) pour former le classifie
ur.
 Ensuite, extraire les caractéristiques, et pour cela, les fonctionnalités
 de Haar présentées dans la figure ci-dessous sont utilisées.
 Chaque caractéristique est une valeur unique obtenue par la soustraction
 de la somme des pixels sous le rectangle blanc de la somme des pixels sous
 le rectangle noir.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/bord_features.jpg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Caractéristiques du bord
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/ligne_features.jpg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Caractéristiques de ligne
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/rectangle_features.jpg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Caractéristiques quatre rectangles
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Caractéristiques de Haar
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Cette méthode consiste à parcourir l’intégralité de l’image pour extraire
 un certain nombre de caractéristiques comme ça permet de réduire le nombre
 de calculs relatif à un pixel donné à une opération ne nécessitant que
 quatre pixels.
 Parmi les caractéristiques calculées, il y’en a celles qui sont sans importance
, pour sélectionner que le nombre de caractéristiques importantes Haar Cascade
 utilise l’algorithme d’apprentissage Adaboost pour à la fin obtenir un
 résultat efficace des classifieurs.
\end_layout

\begin_layout Standard
Une fois le visage détecté, il faut en extraire les saillances.
 L’utilisation des caractéristiques rectangulaires de cette méthode permet
 de détecter les yeux ou la bouche sur un visage, et cette fonction est
 disponible dans OpenCV.
 Cette méthode a résolue beaucoup de problèmes rencontrés auparavant dans
 la détection de visage tel que, cette méthode fonctionne presque en temps
 réel sur le processeur, elle en dispose d’une architecture simple et elle
 détecte les visages à différentes échelles.
 Cependant cette méthode reste imprécise, elle donne beaucoup de fausses
 prédictions, elle ne fonctionne pas sur les images non frontales et elle
 ne fonctionne pas sous occlusion.
\end_layout

\begin_layout Subsection
DNN
\end_layout

\begin_layout Standard
La méthode DNN ou Deep Neural Network (réseau de neurones profond) est une
 méthode de détection de visage plus performante basée sur l’apprentissage
 profond aussi appelé deep-learning [2].
 Elle repose sur l’apprentissage, par un ordinateur d’un modèle de données
 servant à remplir une tâche.
 Pour ce faire, un réseau de neurones est modélisé dans l’ordinateur.
 Celui-ci reçoit des images les traite en vue de leur classification par
 le biais de modèle de l’apprentissage profond formé.
 Cette méthode donne en sortie une matrice à quatre dimensions telle que,
 la troisième dimension itère sur les visages détectés tandis que la quatrième
 dimension contient des informations sur le cadre de la sélection et le
 score de chaque visage.
 Les coordonnées de la sortie du cadre de sélection sont normalisées entre
 [0,1].
 Ainsi, les coordonnées doivent être multipliées par la hauteur et la largeur
 de l’image d’origine pour obtenir le cadre de sélection correct sur l’image.
 La méthode DNN surmonte tous les défauts de la détection avec la méthode
 à cascade de Haar, sans compromettre aucun avantage fourni par Haar.
 En plus de ça, c’est la méthode la plus précise dans la détection, elle
 fonctionne en temps réel sur le processeur ainsi elle détecte les visages
 à différentes échelles (visage grand et petit) et elle fonctionne pour
 les différentes orientations du visage (haut, bas, gauche, droite, côté,
 etc) voire même sous occlusion importante.
 Actuellement le méthode DNN ne présente aucun inconvénient majeur d’après
 les dernières recherches faites en fin 2018 par rapport à toutes les méthodes
 de détection de visage dans OpenCV sauf qu’elle est plus au moins lente
 que celle basée sur Dlib HOG.
\end_layout

\begin_layout Subsection
HOG
\end_layout

\begin_layout Standard
Il s’agit d’un modèle de détection de visage largement utilisé, basé sur
 les fonctionnalités HOG (Histogram of Oriented Gradients) et SVM (Support
 Vector Machine).
 Dans le descripteur de caractéristiques HOG, la distribution (histogrammes)
 des directions de gradients (gradients orientés) est utilisé comme caractéristi
que.
 Le calcul de l’histogramme des gradients se déroule en quatre étapes.
 La première étape est l’étape de prétraitement, tout d’abord il faut sélectionn
er un patch d’image de l’image initiale et ensuite redimensionner ce patch
 de l’image à une taille plus petite comme le montre la figure suivante.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/resize.jpg
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
La deuxième étape consiste à faire le calcul de dégradé, pour calculer un
 descripteur de HOG, il faut d’abord calculer les gradients horizontaux
 et verticaux.
 Le but est de calculer l’histogramme des gradients.
 Ensuite trouver la magnitude et la direction du gradient.
\end_layout

\begin_layout Standard
La troisième étape consiste à faire le calcul de l’histogramme des gradients
 dans 8 x 8 cellules.
 Dans cette étape, l’image est divisée en 8 x 8 cellules et un histogramme
 de gradients est calculé pour chaque 8 x 8 cellules.
 L’histogramme est essentiellement un vecteur de 9 nombres correspondant
 aux angles 0, 20, 40, …, 160.
 La figure suivante illustre le processus.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/hist_construction.jpg
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Processus de la construction de l’histogramme des gradients
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Ici, le pixel encerclé par le bleu a un angle de 80 degrés et une magnitude
 de 2, donc ajouter 2 à la cinquième case.
 Le dégradé au niveau du pixel entouré de rouge a un angle de 10 degrés
 et une amplitude de 4.
 Comme 10 se situe entre 0 et 20, le pixel se divise dans les deux emplacements
 aux deux premières cases.
\end_layout

\begin_layout Standard
La quatrième étape est la normalisation de bloc 16 x 16, puisque les degrés
 de l’image qui compose l’histogramme construit dans l’étape précédente
 est sensible à la luminosité, il est préférable de normaliser l’histogramme
 afin qu’il ne soit pas affecté par les variations de luminosité.
 Chaque histogramme est un vecteur de 9 x 1, et on peut concaténer 4 histogramme
s donc dans cette étape la normalisation se fait sur un vecteur de 36 x
 1 éléments.
\end_layout

\begin_layout Standard
La dernière étape consiste à calculer le vecteur de caractéristique HOG,
 pour calculer le dernier vecteur de caractéristique pour l’ensemble du
 bloc d’image, les vecteurs de 36 x 1 sont concaténés en un seul vecteur
 géant.
\end_layout

\begin_layout Standard
La méthode HOG est la méthode la plus rapide sur le processeur, elle fonctionne
 très bien pour mes faces frontales et légèrement non frontales, son modèle
 est léger par rapport aux méthodes précédentes et elle fonctionne sous
 petit occlusion.
 Cependant, l’inconvénient majeur de cette méthode est qu’elle ne détecte
 pas les petit visages, car elle est conçue pour une taille minimale de
 80 x 80, la boite englobante exclut souvent une partie du front et même
 une partie menton parfois, elle ne fonctionne pas très bien sous occlusion
 importante et elle ne fonctionne pas pour les faces latérales et les faces
 extrêmes non frontales, comme par exemple regarder vers le bas ou vers
 le haut.
\end_layout

\begin_layout Subsection
Détection de visage avec CNN
\end_layout

\begin_layout Standard
C’est une méthode qui est aussi très utilisée dans cette dernière décennie,
 à cause de sa capacité et la perfection dans l’extraction qui a permet
 aux utilisateurs de se libérer des tâches fastidieuses telles que l’extraction
 minière négative.
 Cette méthode repose sur un algorithme de détection d’objets à marge maximale
 MMOD (Max Margin Object Detection en anglais) Pour Dlib.
 Ce modèle produit des détecteurs de haute qualité à partir de quantités
 relativement faibles de donnée d’entrainement (à partir de 4 images seulement)
 en utilisant un ensemble de données étiqueté manuellement par son auteur.
 Cependant, l’implémentation MMOD utilise l’extraction de caractéristiques
 HOG suivie d’un filtre linéaire unique.
 Cela signifie qu’il capable d’apprendre à détecter des objets présentant
 une variation complexe de pose ou une grande variété d’apparences, ce qui
 a conduit à utiliser au cours des dernières années, les réseaux de neurones
 convolutifs CNN (3) capable de traiter tous ces problèmes dans un seul
 modèle.
 L’idée est donc d’ajouter une implémentation de MMOD avec l’extraction
 de la fonctionnalité HOG remplacée par un réseau de neurones convolutifs.
 Le résultat obtenu avec la version CNN de MMOD était inattendu en travaillant
 seulement avec 4 images étant donné que d’autres méthodes de Deep-learning
 nécessitent généralement plusieurs milliers d’images.
 Les images suivantes montrent la différence de capacité dans la détection
 entre le nouveau détecteur CNN et le détecteur de Dlib par défaut HOG telles
 que, les cases rouges correspondent aux détections CNN et les cases bleues
 aux détections HOG.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/hog_cnn.jpg
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
visages détectés par le détecteur HOG et CNN
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Une différence notable entre les deux modèles de détection, HOG fait un
 excellent travail sur les visages faciles en regardant la caméra, mais
 seulement en étant directement face à la caméra, cependant e détecteur
 CNN est bien meilleur non seulement pour traiter les cas facile mais tous
 les visages en général.
 Il est aussi robuste à l’occlusion, rapide sur les GPUs (45 ms par images)
 et son processus de formation est très facile.
 En revanche, ce modèle reste lent sur mes processus (370 ms pour traiter
 une seule image), il entrainé pour une taille minimale de 80 x 80, ce qui
 fait qu’il ne détecte pas les petits visages et sa boite englobante est
 encire plus petite que le détecteur HOG.
\end_layout

\begin_layout Section
Éxtractions des saillances
\end_layout

\begin_layout Section
Clustering
\end_layout

\begin_layout Standard
Le clustering ou la classification non supervisée en français, est une technique
 de classification très parlante en apprentissage automatique, en analyse
 et en fouille de donnée ainsi qu’en reconnaissance de formes.
 Il fait une partie intégrante de tout un processus d’analyse exploratoire
 de données permettant de produire ses outils de synthétisation, de prédiction,
 de visualisation et d’interprétation d’un ensemble d’individus (personnes,
 objets, processus, etc.).
 L’objectif est, à partir de données constituées d’un ensemble d’individus
 ou d’objets et d’une relation de proximité entre ceux-ci, de construire
 des groupes d’individus homogènes dans les sens où :
\end_layout

\begin_layout Itemize
Deux individus proches doivent appartenir à un même ensemble (groupe).
\end_layout

\begin_layout Itemize
Deux individus éloignés doivent appartenir à des groupes différents.
\end_layout

\begin_layout Standard
Afin de définir l’homogénéité d’un groupe d’observation, il est nécessaire
 de mesurer une ressemblance entre deux observations.
 D’où la notion de similarité et de dissimilarité [4]
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/clustering.jpg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Clustering
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Ici, les points originaux ce sont les données constituées par exemple un
 ensemble d’individus, le clustering les partitionne dans des groupes où
 chaque groupe représente un ensemble d’individus qui partagent une même
 caractéristique.
 Le clustering comprend plusieurs algorithmes de classifications pour classifier
 chaque point de données dans un groupe spécifique tels que : k-Means le
 plus algorithme connu dans la classification non supervisée, Mean-Shift
 un algorithme basé sur une fenêtre glissante qui tente de trouver des zones
 senses de points de données, Density-Based Spatial Clustering of Applications
 with Noise (DBSCAN), un algorithme basé sue la densité similaire au décalage
 moyen, Expectation-Maximization (EM) à l’aide de Modèles de Mélange Gaussiens
 (GMM) et Self Organisation Map (SOM).
 Dans ce qui suit nous allons nous intéressés aux deux algorithmes suivent
 k-Means et l’algorithme Safe Organizen Map (SOM).
\end_layout

\begin_layout Subsection
K-means
\end_layout

\begin_layout Standard
K-Means est probablement l’algorithme de classification le plus connu.
 C’est un algorithme facile à comprendre et à implémenter.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/kmeans_avant.jpg
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
avant le clustering
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/kmeans_apres.jpg
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
aprés le clustering
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
K-means clustering
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
La figure ci-dessus montre un exemple de classification par l’algorithme
 k-Means, tels que les points noirs à droites sont les points de données
 de départs et à la fin on affecte chaque point dans son groupe, ici nous
 avons trois groupes (groupes des points bleus, verts et rouges).
\end_layout

\begin_layout Standard
Pour commencer, nous avons d’abord sélectionnés un certain nombre de classes
 (groupes) à utiliser en initialisant aléatoirement leurs points centraux
 respectifs.
 Dans notre exemple nous avons trois classes.
 Les points centraux sont des vecteurs de la même longueur que chaque vecteur
 de points de données.
\end_layout

\begin_layout Standard
Chaque point de données (points noirs) est classé en calculant la distance
 entre ce point et chaque centre de groupe, puis en classant le point dans
 le groupe dont le centre est le plus proche.
 Sur la base de ces points classés, nous recalculons le centre du groupe
 en prenant la moyenne de tous les vecteurs du groupe.
\end_layout

\begin_layout Standard
Nous répétons cette étape pour un nombre défini d’itérations ou jusqu’à
 ce que les centres de groupe ne changent plus beaucoup d’une itération
 à une autre.
 Comme il est possible de choisir d’initialiser plusieurs fois le centre
 de groupe de manière aléatoire, puis de sélectionner le cycle qui donne
 les meilleurs résultats.
\end_layout

\begin_layout Standard
K-Means a l’avantage d’être assez rapide, car nous ne faisons que calculer
 les distances entre les points et les centres de groupe.
 Très peu de calculs, sa complexité linéaire est O (n).
\end_layout

\begin_layout Standard
D’autres parts, K-Means présente quelques inconvénients.
 Tout d’abord, nous devons sélectionner le nombre de groupes (classes).
 Ce n’est pas toujours évident et idéalement avec un algorithme de classificatio
n, nous aimerions qu’il soit mieux compris pas ceux-ci, car il s’agit là
 d’obtenir un aperçu des données.
 K-Means commence également par un choix aléatoire de centre de grappes
 et peut donc donner différents résultats de frappes dur différentes exécutions
 de l’algorithme.
 Ainsi, les résultats peuvent ne pas être reproductible et manquer de cohérences.
\end_layout

\begin_layout Subsection
Carte auto-organisatrice (SOM)
\end_layout

\begin_layout Standard
Self Organizen Map ou la carte auto organisatrice (SOM), est un type de
 réseau de neurones artificiels (RNA) formé à l’aide d’un apprentissage
 non supervisé afin de produire une représentation discrète, généralement
 bidimensionnelle, de l’espace d’entrée des échantillons d’apprentissage.
 La carte est donc une méthode pour faire la réduction de dimensionnalité.
 Les carte auto organisatrices différent des autres réseaux de neurones
 artificiels par le fait qu’elles appliquent l’apprentissage compétitif
 par opposition à l’apprentissage avec correction d’erreur et qu’elles utilisent
 une fonction de voisinage pour préserver les propriétés topologiques de
 l’espace d’entrée.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/som.jpg
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Réduction de la dimensionnalité dans la SOM
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
SOM a été introduite par le professeur finlandais Teuvo Kohonen dans les
 années 1980, elle est aussi appelée carte de Kohonen.
\end_layout

\begin_layout Standard
Chaque point de données dans l’ensemble des points de données se reconnait
 en compétition pour la représentation.
 Les étapes de mappage SOM commencent par l’initialisation des vecteurs
 de pondération.
 A partir de là, un vecteur d’échantillon est sélectionné de manière aléatoire
 et la carte des vecteurs de poids est explorée pour trouver quel poids
 représente le mieux cet échantillon.
 Chaque vecteur de poids a des poids voisins qui lui sont proches.
 Le poids choisi est récompensé par sa capacité de ressembler davantage
 à cet échantillon de vecteur sélectionné au hasard.
 Les voisins de ce poids sont également récompensés par leur capacité à
 ressembler davantage au vecteur échantillon choisi.
 Cela permet à la carte de s’agrandir et de former différentes formes.
 Plus généralement, ils forment des formes carrées, rectangulaires, hexagonales
 et L dans un espace de fonction 2D.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/decision_som.jpg
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Illustration de la décision de base à prendre lors de la croissance
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
L’algorithme SOM :
\end_layout

\begin_layout Enumerate
Initialiser chaque poids de chaque nœud.
\end_layout

\begin_layout Enumerate
Choisir un vecteur au hasard dans l’ensemble des données d’apprentissages.
\end_layout

\begin_layout Enumerate
Chaque nœud est examiné pour calculer les poids qui ressemblent le plus
 au vecteur d’entrée.
 Le nœud gagnant est généralement appelé unité de meilleure correspondance
 ou Best Matching Unit (BMU)
\end_layout

\begin_layout Enumerate
Le poids gagnant est récompensé par le fait de ressembler davantage au vecteur
 échantillon.
 Les voisins deviennent également davantage comme le vecteur échantillon.
 Plus le nœud est proche du BMU, plus des poids sont modifiés et plus le
 voisin est éloigné du BMU, moins il en apprend.
\end_layout

\begin_layout Enumerate
Répéter l’étape 2 pour N itération.
\end_layout

\begin_layout Standard
BMU est technique qui calcul la distance entre chaque poids et le vecteur
 échantillon en parcourant tous les vecteurs de poids.
 Le poids avec la distance la plus courte est le gagnant.
 Il existe nombreuse façon de déterminer la distance, cependant la méthode
 la plus couramment utilisée est la distance euclidienne.
\end_layout

\begin_layout Section*
Conclusion
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{section}{Conclusion}
\end_layout

\end_inset


\end_layout

\end_body
\end_document
