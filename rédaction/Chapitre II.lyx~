#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass report
\begin_preamble
\usepackage[bottom]{footmisc}
\usepackage{fancyhdr}
\pagestyle{fancy}
\usepackage{minitoc}
\usepackage{pgfplots}
\usepackage{lmodern}

\usepackage{titletoc}% http://ctan.org/pkg/titletoc
\titlecontents{chapter}% <section-type>
  [0pt]% <left>
  {\bfseries}% <above-code>
  {\chaptername\ \thecontentslabel:\quad}% <numbered-entry-format>
  {}% <numberless-entry-format>
  {\hfill\contentspage}% <filler-page-format>

\fancyhead[R,C]{}
\fancyhead[L]{\footnotesize\leftmark}
\renewcommand{\headrulewidth}{1pt}
\fancyfoot[L,C]{}
\fancyfoot[R]{\thepage}
\renewcommand{\footrulewidth}{0pt}

\oddsidemargin = 18pt
\topmargin = 0pt
\headheight = 22pt
\headsep = 25pt
\textheight = 609pt
\textwidth = 424pt
\marginparsep = 11pt
\marginparwidth = 54pt
\footskip = 50pt
\marginparpush = 54pt
\hoffset = 0pt
\voffset = 0pt
\end_preamble
\use_default_options true
\begin_modules
theorems-bytype
\end_modules
\maintain_unincluded_children false
\language french
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement h
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\headheight 3cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style swiss
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\bullet 1 0 8 -1
\bullet 2 0 9 -1
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
État de l'art
\end_layout

\begin_layout Quotation
\align right

\emph on
\begin_inset Quotes cld
\end_inset

...ce que nous voulons, c'est une machine qui peut apprendre de l'expérience
\begin_inset Quotes crd
\end_inset

.
 A.
 Turing.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
minitoc
\end_layout

\begin_layout Plain Layout


\backslash
thispagestyle{empty}
\end_layout

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Introduction
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{section}{Introduction}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Dans le but de faciliter la compréhension de notre solution dans le chapitre
 prochain, nous introduisons dans ce chapitre les differentes notions de
 base employé, ainsi, nous présentons les méthodes existantes pour les different
s phases, de la détection du visage jusqu'à la classification non supervisé.
\end_layout

\begin_layout Section
Méthodes de détection de visage
\end_layout

\begin_layout Standard
La détection d'objet est d’identifier quels vobjets se trouvent à l’intérieur
 d’une image et où ils se trouvent.
 C'est un type d’application classé dans la technologie de vision par ordinateur
, et aussi le processus au cours duquel des algorithmes sont développés
 et formés pour localiser correctement les visages ou les objets.
 Celles-ci peuvent être en tems réel à partir d’une caméra vidéo.
 Afin de détecter la position des visages dans les images de sorte à obtenir
 une région d’intérêt sur laquelle l’extraction des vecteurs de caractéristiques
 pourra être accomplie il y a bien de nombreuses méthodes, dans ce qui suit
 nous allons présenter les méthodes les plus utilisées dans la détection.
\end_layout

\begin_layout Subsection
Détection avec la méthode de Viola et Jones
\end_layout

\begin_layout Standard
Les cascades de Haar est une méthode utilisée pour la détection d’objet
 de classificateurs en cascade basés sur les fonctionnalités Haar, c’est
 une méthode efficace de détection d’objets proposée par Paul Viola et Michel
 Jones en 2001 [https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pd
f].
 Il s’agit d’une approche basée sur l’apprentissage automatique.
\end_layout

\begin_layout Standard
La fonction cascade est formée à partir de nombreuses images positives et
 négatives.
 Il est par la suite utilisé pour détecter des objets dans d’autres images.
 Cette méthode travaille avec la détection de visage.
 Initialement, l’algorithme nécessite beaucoup d’images positives (image
 de visage) et d’images négatives (images sans visages) pour former le classifie
ur.
 Ensuite, extraire les caractéristiques, et pour cela, les fonctionnalités
 de Haar présentées dans la figure ci-dessous sont utilisées.
 Chaque caractéristique est une valeur unique obtenue par la soustraction
 de la somme des pixels sous le rectangle blanc de la somme des pixels sous
 le rectangle noir.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/bord_features.jpg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Caractéristiques du bord
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/ligne_features.jpg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Caractéristiques de ligne
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/rectangle_features.jpg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Caractéristiques quatre rectangles
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Caractéristiques de Haar
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Cette méthode consiste à parcourir l’intégralité de l’image pour extraire
 un certain nombre de caractéristiques comme ça permet de réduire le nombre
 de calculs relatif à un pixel donné à une opération ne nécessitant que
 quatre pixels.
 Parmi les caractéristiques calculées, il y’en a celles qui sont sans importance
, pour sélectionner que le nombre de caractéristiques importantes Haar Cascade
 utilise l’algorithme d’apprentissage Adaboost 
\begin_inset CommandInset citation
LatexCommand cite
key "vocaltechnologies"
literal "false"

\end_inset

 pour à la fin obtenir un résultat efficace des classifieurs.
\end_layout

\begin_layout Standard
Une fois le visage détecté, il faut en extraire les saillances.
 L’utilisation des caractéristiques rectangulaires (caractéristiques calculées
 par la différence des sommes des pixels de deux ou plusieurs zones rectangulair
es adjacentes) de cette méthode permet de détecter les yeux ou la bouche
 sur un visage, et cette fonction est disponible dans OpenCV.
 Cette méthode des Haar a résolu beaucoup de problèmes rencontrés auparavant
 dans la détection de visage tel que, cette méthode fonctionne presque en
 temps réel sur le processeur, elle en dispose d’une architecture simple
 et elle détecte les visages à différentes échelles.
 Cependant cette méthode reste imprécise, elle donne beaucoup de fausses
 prédictions, elle ne fonctionne pas sur les images non frontales et elle
 ne fonctionne pas sous occlusion.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "subsec:Histogrammes-de-gradients"

\end_inset

 Détection avec la l'Histogrammes de gradients orientées (HOG)
\end_layout

\begin_layout Standard
L'Histogramme des Gradients Orientés (HOG) est un descripteur de caractéristique
s utilisé dans la vision pas ordinateur et le traitement d'images pour la
 détection d'objets.
 Il s’agit d’un modèle de détection de visage largement utilisé, inventé
 en 2005 par N.
 Dalal et B.Triggs 
\begin_inset CommandInset citation
LatexCommand cite
key "dalal2005histograms"
literal "false"

\end_inset

, basé sur SVM (Support Vector Machine).
\end_layout

\begin_layout Standard
Dans le descripteur de caractéristiques HOG, la distribution (histogrammes)
 des directions de gradients (gradients orientés) est utilisé comme caractéristi
que.
 Le calcul de l’histogramme des gradients se déroule en différentes étapes.
\end_layout

\begin_layout Standard
Tout abord, nous allons mettre l’image en noir et blanc, nous enlevons toutes
 les autres couleurs car nous n’avons pas besoins de couleurs pour trouver
 un visage.
 Ensuite, sélectionner un patch d’image de l’image initiale et redimensionner
 ce patch de l’image à une taille plus petite dans le but de regarder chaque
 pixel de notre image.
 Pour chaque pixel, nous voulons regarder les pixels qui l’entourent directement.
 Le but est de déterminer l’obscurité du pixel courant par rapport aux pixels
 qui l’entourent.
 Ensuite dessiner une flèche pour montrer dans quelle direction l’image
 devient plus sombre comme le montre la figure ci-dessous :
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/gradient1.jpg
	height 100bp

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/gradient2.jpg
	height 100bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
construction du gradient orienté
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
En répétant ce processus, chaque pixel sera remplacé par une flèche.
 Ces flèches sont appelées gradients et elles montrent l’écoulement de la
 lumière à l’obscurité sur toute l’image.
\end_layout

\begin_layout Standard
La raison majeure pour laquelle cette méthode remplace les pixels par des
 flèches est pour avoir une représentation plus 
\begin_inset Quotes cld
\end_inset

robuste
\begin_inset Quotes crd
\end_inset

 aux conditions des images.
 En analysant directement les pixels, pour la même personne, les images
 vraiment sombres et les images vraiment claires auront des valeurs de pixels
 totalement différentes.
 En revanche, en considérant seulement la direction dans laquelle la direction
 change, nous arrivons à une seule représentation finale.
\end_layout

\begin_layout Standard
Cependant, sauvegarder le gradient pour chaque pixel nous donne beaucoup
 de détails et cela fait beaucoup de données, pour cela, nous allons découper
 l’image en petits carrés de 16x16 pixels chacun.
 Et pout chaque case, on comptera combien de pentes dans chaque direction
 principale (vers le haut, haut droit, haut gauche, etc.…).
 Ensuite, nous remplaçons ce carré dans l’image par la direction des flèches.
 A la fin, on arrive à transformer l’image originale en une représentation
 très simple qui capture la structure de base d’un visage de manière très
 simple.
\end_layout

\begin_layout Standard
Enfin, on calcule le vecteur de caractéristiques HOG, ce dernier est un
 grand vecteur qui concatène plusieurs vecteurs de caractéristique de l’ensemble
 de l’image pour chaque carré de cette image comme il est illustré dans
 la figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Processus-de-la"
plural "false"
caps "false"
noprefix "false"

\end_inset

 ci-aprés.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/hist_gradients.jpg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Processus-de-la"

\end_inset

Processus de la construction de l’histogramme des gradients
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
La dernière étape consiste à calculer le vecteur de caractéristique HOG,
 pour calculer le dernier vecteur de caractéristique pour l’ensemble du
 bloc d’image, les vecteurs de 36 x 1 sont concaténés en un seul vecteur
 géant.
\end_layout

\begin_layout Standard
La méthode HOG est la méthode la plus rapide sur le processeur d'après 
\begin_inset CommandInset citation
LatexCommand cite
key "gupta_2018"
literal "false"

\end_inset

, elle fonctionne très bien pour les faces frontales et légèrement pour
 les non frontales et elle fonctionne sous petit occlusion.
 Cependant, l’inconvénient majeur de cette méthode est qu’elle ne détecte
 pas les petits visages, car elle est conçue pour une taille minimale de
 80 x 80, la région d'interêt exclut souvent une partie du front et même
 une partie du menton parfois, elle ne fonctionne pas très bien sous occlusion
 importante et elle ne fonctionne pas pour les faces latérales et les faces
 extrêmes non frontales, comme par exemple regarder vers le bas ou vers
 le haut.
\end_layout

\begin_layout Subsection
Autre méthodes de détection
\end_layout

\begin_layout Standard
Il existe d'autres méthodes de détection de visage parmis ces méthodes,
 la méthode de Single Shot MultiBox Detector (SSD) proposé par W.
 Liu et all.
 dans 
\begin_inset CommandInset citation
LatexCommand cite
key "liu2016ssd"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Ce descripteur surmonte tous les défauts de la détection avec la méthode
 à cascade de Haar selon 
\begin_inset CommandInset citation
LatexCommand cite
key "gupta_2018"
literal "false"

\end_inset

, sans compromettre aucun avantage fourni par Haar.
 En plus de ça, c’est la méthode la plus précise dans la détection, elle
 fonctionne en temps réel sur le processeur ainsi elle détecte les visages
 à différentes échelles (visage grand et petit) et elle fonctionne pour
 les différentes orientations du visage (haut, bas, gauche, droite, côté,
 etc) voire même sous occlusion importante.
 Actuellement le méthode SSD ne présente aucun inconvénient majeur par rapport
 à toutes les méthodes de détection de visage dans OpenCV sauf qu’elle est
 plus au moins lente que celle basée sur Dlib HOG avec les CNN.
\end_layout

\begin_layout Standard
Un autre méthode aussi impourante dans la détection de visage, la méthode
 Max Margin Object Detection (MMOD) proposé par Davis E.
 King dans 
\begin_inset CommandInset citation
LatexCommand cite
key "king2015max"
literal "false"

\end_inset

.
 Son modèle est le plus rapide sur les GPUs (45 ms par images), il est aussi
 robuste à l’occlusion et son processus de formation est très facile.
 En revanche, ce dernier, reste lent sur les processus (370 ms pour traiter
 une seule image), il est entrainé pour une taille minimale de 80 x 80,
 ce qui fait qu’il ne détecte pas les petits visages et sa boite englobante
 est encore plus petite que le détecteur HOG avec SVM.
\end_layout

\begin_layout Standard
.
\end_layout

\begin_layout Section
Methode d'extraction des points de saillances 
\begin_inset CommandInset citation
LatexCommand cite
key "kazemi2014one"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
Le processus qui est capable d’explorer un ensemble de points clés à partir
 d’une image de visage donnée, est appelée Localisation du repère du visage
 ou Face Landmark Localization en anglais (alignement du visage).
\end_layout

\begin_layout Standard
Les repères (points clés) qui nous intéressent sont ceux qui décrivent la
 forme des attributs du visage comme : les yeux, les sourcils, le nez, la
 bouche, et le menton.
 Ces points ont donné un excellent aperçu de la structure faciale analysée,
 qui peut être très utile pour un large éventail d’applications.
\end_layout

\begin_layout Standard
De nombreuses méthodes permettent de détecter ces points : certaines d’entres
 elles atteignent une précision et une robuste supérieures en analysant
 un modèle de visage 3D extrait d’une image 2D, d’autres s’appuient sur
 la puissance des CNN et d’autres utilisent des fonctions simples (mais
 rapides) pour estimer l’emplacement des points.
\end_layout

\begin_layout Standard
L’Algorithme de détection des repères de visage proposé par Dlib est l’implément
ation de l’Ensemble of Regression Trees (
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "ERT"
description "Ensemble of Regression Trees"
literal "false"

\end_inset

ERT) présenté en 2014 par Kazemi et Sullivan 
\begin_inset CommandInset citation
LatexCommand cite
key "kazemi2014one"
literal "false"

\end_inset

.
 Cette technique utilise une fonction simple et rapide (différence d’intensité
 des pixels) pour estimer directement la position des points de repère.
 Ces positions estimées sont ensuite affinées au moyen d’un processus itératif
 effectué par une cascade de variables explicatives.
 Les régresseurs produisent une nouvelle estimation à partir de la précédente,
 en essayant de réduire l’erreur d’alignement des points estimés à chaque
 itération.
 L’algorithme est très rapide, en fait, il faut environ 1 à 3 ms pour détecter
 un ensemble de 68 points de repère sur un visage donné.
 La figure suivante présente l’ensemble des points de visage extrait par
 l’algorithme :
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/68pointsdlib.jpg
	scale 80

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:L'ensemble-des-68"

\end_inset

L'ensemble des 68 points détectés par Dlib pré-entraîné
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
La région du visage peut être facilement obtenue par n’importe quel algorithme
 de détection de visage (OpenCV Haar Cascade, Dlib HOG Detector, CNN, .
 .
 .
 ).
 Enfin, les options de formation sont un ensemble de paramètres qui définissent
 les caractéristiques du modèle formé.
 Ces paramètres peuvent être correctement ajustés afin d’obtenir le comportement
 souhaité du modèle généré.
\end_layout

\begin_layout Section
Clustering
\end_layout

\begin_layout Standard
Le clustering ou la classification non supervisée en français, est une technique
 de classification en apprentissage automatique, en analyse et en fouille
 de donnée ainsi qu’en reconnaissance de formes.
 Il fait une partie intégrante de tout un processus d’analyse exploratoire
 de données permettant de produire ses outils de synthétisation, de prédiction,
 de visualisation et d’interprétation d’un ensemble d’individus (personnes,
 objets, processus, etc.).
 L’objectif est, à partir de données constituées d’un ensemble d’individus
 ou d’objets et d’une relation de proximité entre ceux-ci, de construire
 des groupes d’individus homogènes dans les sens où :
\end_layout

\begin_layout Itemize
Deux individus proches doivent appartenir à un même ensemble (groupe).
\end_layout

\begin_layout Itemize
Deux individus éloignés doivent appartenir à des groupes différents.
\end_layout

\begin_layout Standard
Afin de définir l’homogénéité d’un groupe d’observation, il est nécessaire
 de mesurer une ressemblance entre deux observations.
 D’où la notion de similarité et de dissimilarité comme la montre la figure
 1.5 : 
\begin_inset CommandInset citation
LatexCommand cite
key "ClassNonSup"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/clustering.jpg

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Clustering
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Ici, les points originaux ce sont les données constituées par exemple d'un
 ensemble d’individus, le clustering les partitionne dans des groupes où
 chaque groupe représente un ensemble d’individus qui partagent une même
 caractéristique.
 Le clustering comprend plusieurs algorithmes de classifications pour classifier
 chaque point de données dans un groupe spécifique tels que : k-Means, Mean-Shif
t, Density-Based Spatial Clustering of Applications with Noise (DBSCAN),
 Expectation-Maximization (EM) à l’aide de Modèles de Mélange Gaussiens
 (GMM) et Self Organising Map (SOM).
 Dans ce qui suit nous allons nous intéressés aux deux algorithmes suivent
 k-Means et l’algorithme Safe Organising Map (SOM).
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "subsec:K-means"

\end_inset

K-means 
\begin_inset CommandInset citation
LatexCommand cite
key "raval2016implementing"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
K-Means est probablement l’algorithme de classification le plus connu.
 C’est un algorithme facile à comprendre et à implémenter.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/kmeans_avant.jpg
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
avant le clustering
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/kmeans_apres.jpg
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
aprés le clustering
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
K-means clustering
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
La figure ci-dessus montre un exemple de classification par l’algorithme
 k-Means, tels que les points noirs à droites sont les points de données
 de départs et à la fin on affecte chaque point dans son groupe, ici nous
 avons trois groupes (groupes des points bleus, verts et rouges).
\end_layout

\begin_layout Standard
Pour commencer, nous avons d’abord sélectionnés un certain nombre de classes
 (groupes) à utiliser en initialisant aléatoirement leurs points centraux
 respectifs.
 Dans notre exemple nous avons trois classes.
 Les points centraux sont des vecteurs de la même longueur que chaque vecteur
 de points de données.
\end_layout

\begin_layout Standard
Chaque point de données (points noirs) est classé en calculant la distance
 entre ce point et chaque centre de groupe, puis en classant le point dans
 le groupe dont le centre est le plus proche.
 Sur la base de ces points classés, nous recalculons le centre du groupe
 en prenant la moyenne de tous les vecteurs du groupe.
\end_layout

\begin_layout Standard
Nous répétons cette étape pour un nombre défini d’itérations ou jusqu’à
 ce que les centres de groupe ne changent plus beaucoup d’une itération
 à une autre.
 Comme il est possible de choisir d’initialiser plusieurs fois le centre
 de groupe de manière aléatoire, puis de sélectionner le cycle qui donne
 les meilleurs résultats.
\end_layout

\begin_layout Standard
K-Means a l’avantage d’être assez rapide, car nous ne faisons que calculer
 les distances entre les points et les centres de groupe.
 Très peu de calculs, sa complexité linéaire est O (n).
\end_layout

\begin_layout Standard
D’autres parts, K-Means présente quelques inconvénients.
 Tout d’abord, nous devons sélectionner le nombre de groupes (classes).
 Ce n’est pas toujours évident et idéalement avec un algorithme de classificatio
n, nous aimerions qu’il soit mieux compris pas ceux-ci, car il s’agit là
 d’obtenir un aperçu des données.
 K-Means commence également par un choix aléatoire de centre de grappes
 et peut donc donner différents résultats des différentes exécutions de
 l’algorithme.
 Ainsi, les résultats peuvent ne pas être reproductible et manquer de cohérences.
\end_layout

\begin_layout Subsection
Carte auto-organisatrice (SOM)
\end_layout

\begin_layout Standard
Self Organising Map ou la carte auto organisatrice (SOM), est un type de
 réseau de neurones artificiels (
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "RNA"
description "réseau de neurones artificiels"
literal "false"

\end_inset

RNA) formé à l’aide d’un apprentissage non supervisé afin de produire une
 représentation discrète, généralement bidimensionnelle, de l’espace d’entrée
 des échantillons d’apprentissage.
 La carte est donc une méthode pour faire la réduction de dimensionnalité.
 Les cartes auto organisatrices différent des autres réseaux de neurones
 artificiels par le fait qu’elles appliquent l’apprentissage compétitif
 par opposition à l’apprentissage avec correction d’erreur et qu’elles utilisent
 une fonction de voisinage pour préserver les propriétés topologiques de
 l’espace d’entrée.
 La figure ci-dessous montre la construction de la map à partir d'un ensemble
 de vecteurs d'entrés : 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename D:/E/InitRec/som.jpg
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Réduction de la dimensionnalité dans la SOM
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
SOM a été introduite par le professeur finlandais Teuvo Kohonen dans les
 années 1980 [)https://sci2s.ugr.es/keel/pdf/algorithm/articulo/1990-Kohonen-PIEEE.
pdf], elle est aussi appelée carte de Kohonen 
\begin_inset CommandInset citation
LatexCommand cite
key "kohonen1990self"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Chaque point de données dans l’ensemble des points de données se reconnait
 en compétition pour la représentation.
 Les étapes de mappage SOM commencent par l’initialisation des vecteurs
 de pondération.
 A partir de là, un vecteur d’échantillon est sélectionné de manière aléatoire
 et la carte des vecteurs de poids est explorée pour trouver quel poids
 représente le mieux cet échantillon.
 Chaque vecteur de poids a des poids voisins qui lui sont proches.
 Le poids choisi est récompensé par sa capacité de ressembler davantage
 à cet échantillon de vecteur sélectionné au hasard.
 Les voisins de ce poids sont également récompensés par leur capacité à
 ressembler davantage au vecteur échantillon choisi.
 Cela permet à la carte de s’agrandir et de former différentes formes.
 Plus généralement, ils forment des formes carrées, rectangulaires, hexagonales
 et L dans un espace de fonction 2D.
\end_layout

\begin_layout Subsubsection*
L’algorithme SOM :
\end_layout

\begin_layout Enumerate
Initialiser chaque poids de chaque nœud.
\end_layout

\begin_layout Enumerate
Choisir un vecteur au hasard dans l’ensemble des données d’apprentissages.
\end_layout

\begin_layout Enumerate
Chaque nœud est examiné pour calculer les poids qui ressemblent le plus
 au vecteur d’entrée.
 Le nœud gagnant est généralement appelé unité de meilleure correspondance
 ou Best Matching Unit (
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "BMU"
description "Best Matching Unit"
literal "false"

\end_inset

BMU)
\end_layout

\begin_layout Enumerate
Le poids gagnant est récompensé par le fait de ressembler davantage au vecteur
 échantillon.
 Les voisins deviennent également davantage comme le vecteur échantillon.
 Plus le nœud est proche du BMU, plus des poids sont modifiés et plus le
 voisin est éloigné du BMU, moins il en apprend.
\end_layout

\begin_layout Enumerate
Répéter l’étape 2 pour N itération.
\end_layout

\begin_layout Standard
BMU est technique qui calcul la distance entre chaque poids et le vecteur
 échantillon en parcourant tous les vecteurs de poids.
 Le poids avec la distance la plus courte est le gagnant.
 Il existe nombreuse façon de déterminer la distance, cependant la méthode
 la plus couramment utilisée est la distance euclidienne.
\end_layout

\begin_layout Section*
Conclusion
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{section}{Conclusion}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Nous avons exploré, dans ce chapitre, les différents notions, existantes,
 liées à notre solution.
 Cela nous permet d’entamer les détails de notre conception dans le chapitre
 suivant.
\end_layout

\end_body
\end_document
