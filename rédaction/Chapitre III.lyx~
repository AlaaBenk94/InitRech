#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass report
\begin_preamble
\usepackage[bottom]{footmisc}
\usepackage{fancyhdr}
\pagestyle{fancy}
\usepackage{minitoc}
\usepackage{pgfplots}
\usepackage{lmodern}

\usepackage{titletoc}% http://ctan.org/pkg/titletoc
\titlecontents{chapter}% <section-type>
  [0pt]% <left>
  {\bfseries}% <above-code>
  {\chaptername\ \thecontentslabel:\quad}% <numbered-entry-format>
  {}% <numberless-entry-format>
  {\hfill\contentspage}% <filler-page-format>

\fancyhead[R,C]{}
\fancyhead[L]{\footnotesize\leftmark}
\renewcommand{\headrulewidth}{1pt}
\fancyfoot[L,C]{}
\fancyfoot[R]{\thepage}
\renewcommand{\footrulewidth}{0pt}

\oddsidemargin = 18pt
\topmargin = 0pt
\headheight = 22pt
\headsep = 25pt
\textheight = 609pt
\textwidth = 424pt
\marginparsep = 11pt
\marginparwidth = 54pt
\footskip = 50pt
\marginparpush = 54pt
\hoffset = 0pt
\voffset = 0pt
\end_preamble
\use_default_options true
\begin_modules
theorems-bytype
\end_modules
\maintain_unincluded_children false
\language french
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement h
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\headheight 3cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style swiss
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\bullet 1 0 8 -1
\bullet 2 0 9 -1
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Analyse et réalisation
\end_layout

\begin_layout Quotation
\align right

\emph on
\begin_inset Quotes cld
\end_inset

...si vous ne pouvez pas l'expliquer simplement, vous ne le comprenez pas assez
 bien.
\begin_inset Quotes crd
\end_inset

.
 A.
 Einstein.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
minitoc
\end_layout

\begin_layout Plain Layout


\backslash
thispagestyle{empty}
\end_layout

\begin_layout Plain Layout


\backslash
newpage
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Introduction
\end_layout

\begin_layout Standard
Les deux premiers chapitres étaient une introduction au contexte du projet
 ainsi q'une présentation de toutes les notions importantes pour la compréhensio
n de l'approche.
\end_layout

\begin_layout Standard
Dans ce chapitre, nous présentrons les différentes étapes de l'approche
 suivie en expliquant ce que nous avons utilisé dans chacune de ces étapes.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{section}{Introduction}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Appoche globale
\end_layout

\begin_layout Standard
Notre objectif, comme mentionné précédemment, est de concevoir un système
 qui permet à la lampe de réagir en fonction des changements des expressions
 du sujet qui se trouve en face d'elle.
\end_layout

\begin_layout Standard
La réalisation de ce système nécessite de passer par plusieurs étapes indispensa
bles en commençant par la détection de visage et l'extraction des points
 de saillances.
 Ensuite nous allons passer à l'extraction des caractéristiques et l'encodage
 des solutions.
 Enfin, nous arrivons au regroupement (clustering) des différents changements
 et à la définition du comportement.
\end_layout

\begin_layout Standard
Pour simplifier la compréhension du fonctionnement de l'approche suivie,
 nous avons jugé utile de partitionner le travail en trois phases (figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Structure-globale-du"
plural "false"
caps "false"
noprefix "false"

\end_inset

) :
\end_layout

\begin_layout Itemize
La phase de préparation qui prend en entrée un flux d'image sous forme d'une
 vidéo (séquences d'images) pour produire en sortie un vecteur de 68 points
 de saillances.
\end_layout

\begin_layout Itemize
La deuxième phase, dite d'extraction des Vecteurs Caractéristiques des Changemen
ts 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "VCC"
description "Vecteurs Caracteristiques des Changements"
literal "false"

\end_inset

VCC, comporte deux étapes : l'extraction des caractéristiques des 
\emph on
expressions
\emph default
 
\emph on
statiques
\emph default
, puis, le calcul des vecteurs caractéristiques des 
\emph on
changements d'expressions
\emph default
.
\end_layout

\begin_layout Itemize
La dernière phase est la phase de décision qui consiste à regrouper les
 vecteurs caractéristiques en entrée afin de décider le comportement à exécuter
 (les commandes à envoyer à la lampe).
\end_layout

\begin_layout Standard
Nous verrons ces phases en détail dans les sections qui suit.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/schema.svg
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Structure-globale-du"

\end_inset

Structure globale du systèùme
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Phase de préparation
\end_layout

\begin_layout Standard
Dans cette section nous entamons la phase de préparation, cette phase a
 pour but d'extraire un vecteur de points de saillances pour les faire passer
 à la phase suivante.
\end_layout

\begin_layout Subsection
Prétraitement
\end_layout

\begin_layout Standard
Le prétraitement est l'étape avant-première (ou l'étape zéro), dans laquelle
 nous récupérons les images RGB de flux vidéo.
 Ensuite, nous les convertirons en niveaux de gris (grayscale) car nous
 n’avons pas besoin des couleurs dans nos prochains traitements (détection
 du visage, extraction des points de saillances…).
 Ces images seront ainsi redimensionnées pour diminuer le temps des traitements.
\end_layout

\begin_layout Standard
Afin d’obtenir de bons résultats dans les prochaines étapes, nous avons
 jugé utile d’appliquer une égalisation d’histogramme en niveaux de gris.
 Cette dernière permet de mieux répartir les intensités des images à faible
 contraste pour obtenir des images de meilleure qualité.
 Un résumé de l’étape de prétraitement est illustré par la figure suivante.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/preprocessing.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Prétraitement
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Détection du visage
\end_layout

\begin_layout Standard
Comme illustré par la figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Détection-de-visage"
plural "false"
caps "false"
noprefix "false"

\end_inset

 ci-dessous, l'étape de détection du visage s’agit de retrouver la zone
 du visage (la région d'intérêt ROI) dans une image sur laquelle nous effectuons
 des traitements par la suite.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/detection.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Détection-de-visage"

\end_inset

Détection de visage
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
La méthode utilisée pour cette étape est l’histogramme de gradient orienté
 (HOG) décrit dans (section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Histogrammes-de-gradients"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 Le modèle, selon 
\begin_inset CommandInset citation
LatexCommand cite
key "gupta_2018"
literal "false"

\end_inset

, est très léger, il permet de de détecter les visages dans la plupart des
 cas avec un temps du réponse très court.
 De plus, son implémentation est fournie par la bibliothèque dlib 
\begin_inset CommandInset citation
LatexCommand cite
key "dliblibrary"
literal "false"

\end_inset

.
 Comme indiquée dans la section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Histogrammes-de-gradients"
plural "false"
caps "false"
noprefix "false"

\end_inset

, le modèle ne détecte pas les visages latéraux ou quand le visage est tourné
 vers le bas ou vers le haut, ainsi, la ROI détecté exclut souvent une partie
 du front et même une partie du menton parfois.
\end_layout

\begin_layout Subsection
Éxtraction des points de saillances
\end_layout

\begin_layout Standard
Une fois l’étape de détection de visage est terminée, l’étape d’extraction
 des points de saillances prend place.
 Cette étape utilise la région (
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "ROI"
description "Region Of Interest"
literal "false"

\end_inset

ROI) extraite de l’étape précédente pour déterminer 68 points de saillances.
 Nous allons utiliser un algorithme d’estimations des points de saillances
 qui est basé sur une approche inventée par Vahid Kazemi et Josephine Sullivan
 en 2014 
\begin_inset CommandInset citation
LatexCommand cite
key "kazemi2014one"
literal "false"

\end_inset

 utilisant des arbres de régressions.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/landmarks.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Éxtraction des points de saillances
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
L'idée de base est de définir 68 points spécifiques (appelés repères) qui
 existent sur chaque visage - le haut du menton, le bord extérieur de chaque
 œil, le bord intérieur de chaque sourcil, etc.
 Ensuite, utiliser un algorithme d'apprentissage automatique pour avoir
 un modèle capable de trouver ces 68 points sur n'importe quel visage.
\end_layout

\begin_layout Standard
Ce modèle présente des performances intéressantes, il permet d’extraire
 les 68 points dans la majorité des circonstances.
 De plus, il est disponible dans la même bibliothèque dlib 
\begin_inset CommandInset citation
LatexCommand cite
key "dliblibrary"
literal "false"

\end_inset

 ainsi que c'est le modèle plus compatible avec le modèle de détection choisi,
 néanmoins, il ne s’adapte pas avec les changements extrêmes d’expressions
 (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Limites-de-la-1"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 Cela est due à l’absence des visages avec des expressions extrêmes sur
 les images de base d’apprentissage 
\begin_inset CommandInset citation
LatexCommand cite
key "le2012interactive"
literal "false"

\end_inset

 utilisé pour entrainer le modèle.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/ex1.jpg
	scale 40

\end_inset


\begin_inset Graphics
	filename img/ex2.jpg
	scale 40

\end_inset


\begin_inset Graphics
	filename img/ex3.jpg
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Limites-de-la-1"

\end_inset

Limites de la méthode d'extraction des points de saillances.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Phase d'extraction des VCC
\end_layout

\begin_layout Standard
Cette phase permet en premier, de définir des caractéristiques d’expressions,
 choisis explicitement, à partir des vecteurs de points de saillances.
 Ensuite, utiliser ces caractéristiques pour calculer les vecteurs caractéristiq
ues des changements d'expressions qui seront utilisé pour le clustering
 dans la phase qui suit.
\end_layout

\begin_layout Subsection
Éxtraction et encodagedes caractéristique
\end_layout

\begin_layout Standard
Effectuer un apprentissage sur tous les 68 points extraits est, d'une part,
 très couteux en terme du temps et d'espace ainsi, il peuvent générer du
 bruit qui affecte la qualité des résultat obtenus.
 Par conséquent, nous allons extraire, à partir de ces points, des caractéristiq
ues qui nous permettent de distinguer les différentes expressions du visage.
 Nous avons considéré neuf caractéristiques (à savoir : distance des sourcils,
 ouverture des yeux, position du visage, ouverture de la bouche et la rotation
 du visage), ils sont illustrés sur la figure ci-dessous.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/features.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Éxtraction des caractéristiques
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Dans notre expérience, la lampe robotisée est mise devant différentes personnes
 voire les mêmes personnes peuvent se retrouver à des distances différentes
 de la lampe.
 Cela engendre une diversité de valeurs des caractéristiques définis ci-dessus
 pour chaque personne et aussi pour la même personne avec des différentes
 distances (voire la figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Exemple-du-problème"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 De ce fait, il est nécessaire de normaliser ce vecteur des caractéristiques
 pour que la diversité des personnes (ou leurs distances de la caméra) n'affecte
 pas les résultats retournés.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/avantage_normalisation.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Exemple-du-problème"

\end_inset

Exemple du problème de representation des distances sans normalisation
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Nous avons donc normalisé chacune des valeurs de nos caractéristiques entre
 0 et 1, en prenant le rapport des caractéristiques sur des distances fixes
 dans le visage.
 Les détails des calculs sont présentés ci-dessous.
 Les points utilisé dans les formules sont présenté par la figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:L'ensemble-des-68"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 De plus, l'utilisation de la moyenne sur les points permet d'obtenir des
 valeurs plus stables que prendre qu'un seul point.
\end_layout

\begin_layout Subsubsection
Écartement des sourcils
\end_layout

\begin_layout Standard
L'écartement des sourcils est calculé en fonction de la distance sourcil-œil
 et la distance sourcil-sourcil.
 Nous avons utilisé la formule suivante (sourcil droite):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
EcartementSourcil=\frac{\left\Vert P_{24}\cdot Moy(P_{42}...P_{47})\right\Vert }{\left\Vert P_{21}\cdot P_{22}\right\Vert }
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
avec : 
\begin_inset Formula $P_{i}$
\end_inset

: le point numero 
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $Moy(X_{i}...X_{n})$
\end_inset

 : la moyenne (le centre) des points 
\begin_inset Formula $X_{i}$
\end_inset

 jusqu'à 
\begin_inset Formula $X_{n}$
\end_inset

et 
\begin_inset Formula $\left\Vert x\cdot y\right\Vert $
\end_inset

 : est la distance euclidienne entre 
\begin_inset Formula $x$
\end_inset

 et 
\begin_inset Formula $y$
\end_inset


\end_layout

\begin_layout Subsubsection
Ouverture des yeux
\end_layout

\begin_layout Standard
L'ouverture des yeux est le rapport entre la largeur d’œil et sa hauteur.
 Elle est calculé par la formule suivante (Oeil droite):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
OuvertureOeil=\frac{\left\Vert Moy(P_{43},P_{44})\cdot Moy(P_{46},P_{47})\right\Vert }{\left\Vert P_{42}\cdot P_{45}\right\Vert }
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
où : 
\begin_inset Formula $P_{i}$
\end_inset

: le point numero 
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $Moy(X_{i}...X_{n})$
\end_inset

 : la moyenne (le centre) des points 
\begin_inset Formula $X_{i}$
\end_inset

 jusqu'à 
\begin_inset Formula $X_{n}$
\end_inset

et 
\begin_inset Formula $\left\Vert x\cdot y\right\Vert $
\end_inset

 : est la distance euclidienne entre 
\begin_inset Formula $x$
\end_inset

 et 
\begin_inset Formula $y$
\end_inset


\end_layout

\begin_layout Subsubsection
Rotation du visage
\end_layout

\begin_layout Standard
La rotation est calculé par la formule suivante :
\end_layout

\begin_layout Standard

\family typewriter
\begin_inset Formula 
\begin{equation}
Rotation=\frac{\left\Vert Moy(P_{0}...P_{3})\cdot Moy(P_{27}...P_{30})\right\Vert }{\left\Vert Moy(P_{27}...P_{30})\cdot Moy(P_{13}...P_{16})\right\Vert }
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
où : 
\begin_inset Formula $P_{i}$
\end_inset

: le point numero 
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $Moy(X_{i}...X_{n})$
\end_inset

 : la moyenne (le centre) des points 
\begin_inset Formula $X_{i}$
\end_inset

 jusqu'à 
\begin_inset Formula $X_{n}$
\end_inset

et 
\begin_inset Formula $\left\Vert x\cdot y\right\Vert $
\end_inset

 : est la distance euclidienne entre 
\begin_inset Formula $x$
\end_inset

 et 
\begin_inset Formula $y$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Ouverture de la bouche
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Subsubsection
Distance visage/caméra
\end_layout

\begin_layout Standard
La distance visage/caméra est difficile à calculer car nous n'avons pas
 assez d'information.
 Donc, nous avons simplifier les calculs en prenant la surface de ROI sur
 la surface de toute l'image :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Distance=\frac{h*w}{H*W}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
où : 
\begin_inset Formula $H$
\end_inset

 : la hauteur de l'image, 
\begin_inset Formula $W$
\end_inset

 la largeur de l'image, 
\begin_inset Formula $h$
\end_inset

 la hauteur de ROI et 
\begin_inset Formula $w$
\end_inset

 sa largeur.
\end_layout

\begin_layout Subsubsection
Position du visage
\end_layout

\begin_layout Standard
La position du visage représente le centre de ROI, elle est calculée en
 fonction des quatre points du coin de ROI.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Position=Moy(C_{0},C_{1},C_{2},C_{3})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
où : 
\begin_inset Formula $C_{i}$
\end_inset

 représente le point du coin 
\begin_inset Formula $i$
\end_inset


\end_layout

\begin_layout Subsection
Vecteurs caractéristiques des changements d'expressions
\end_layout

\begin_layout Standard
Jusqu'à là, nous avons pu extraire les points de saillances et en définir
 des caractéristiques avec.
 Donc on peut passer ces vecteurs pour la prochaine phase pour le clustering
 des expressions.
 Cependant, puisque les gens ont des proportions du visages diffèrentes,
 nous pouvons avoir deux comportements differents pour deux personnes avec
 les mêmes expressions (par exemple l'expression 
\begin_inset Quotes cld
\end_inset

neutre
\begin_inset Quotes crd
\end_inset

).
 Par conséquent, nous nous intéressons au changement des expressions au
 lieu des expressions statiques.
\end_layout

\begin_layout Standard
Pour réaliser cela, il faut traiter plusieurs images (séquence d'images)
 pour qu'on puisse calculer le vecteur caractérisant le changement d'expressions
 sur cette séquence.
\end_layout

\begin_layout Standard
Une approche simple pour le faire, est de prendre les images du flux vidéo
 deux à deux.
 Puis, on calcule le changement entre ces deux images.
 Soient deux images i et j, extraites de flux vidéo dans deux instants différent
s tel que 
\begin_inset Formula $temps(i)<temps(j)$
\end_inset

 .
 D'abord, les étapes de détection du visage, d'extraction des points de
 saillances et d'extraction des caractéristiques sont effectués sur ces
 deux images pour avoir les vecteurs caractéristiques 
\begin_inset Formula $Vi$
\end_inset

 (respectivement 
\begin_inset Formula $Vj$
\end_inset

) des images 
\begin_inset Formula $i$
\end_inset

 (respectivement 
\begin_inset Formula $j$
\end_inset

).
 Ensuite, nous calculons le 
\emph on
vecteur caractéristique des changements
\emph default
 en appliquant une simple soustraction 
\begin_inset Formula $Vj-Vi$
\end_inset

 sauf pour la position, nous calculons la distance euclidienne.
 Nous obtenons finalement un vecteur caractérisant les changements entre
 l'image 
\begin_inset Formula $i$
\end_inset

 et l'image 
\begin_inset Formula $j$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/VCC.svg
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Calcul des vecteurs caractèristiques des changements
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Phase de décision
\end_layout

\begin_layout Standard
La dernière phase de l'approche, est celle de décision, dans laquelle nous
 prenons les vecteurs caractéristiques issues de la phase antérieure, et
 on y applique les algorithmes d’apprentissage KMeans et DSOM pour avoir
 en sortie le comportement approprié.
\end_layout

\begin_layout Standard
Nous pouvons formuler cela sous forme d'un problème d’apprentissage non
 supervisé discret où les des données sont les vecteurs caractéristiques
 des changements d'expresions et les clusters, ou encore classes ou groupes,
 représente les comportements.
 En effet, nous devons entrainer un modèle 
\begin_inset Formula $f$
\end_inset

 (une fonction de 
\begin_inset Formula $X$
\end_inset

 dans 
\begin_inset Formula $Y$
\end_inset

) qui permet de retourner pour chaque entrée 
\begin_inset Formula $x\in X$
\end_inset

 le comportement approprié 
\begin_inset Formula $y\in Y$
\end_inset

 :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f:\ X\rightarrow Y
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
Avec 
\begin_inset Formula $X$
\end_inset

 ensemble des vecteurs caractéristiques des changements et 
\begin_inset Formula $Y$
\end_inset

 l’ensemble des comportements.
\end_layout

\begin_layout Standard
De plus, l’algorithme doit être capable d’apprendre en temps réel en raffinant
 le modèle à chaque nouvelle donnée d’entrée.
 Ce qui rend la tache plus complexe.
 Pour ce faire, nous avons décider de mettre en place deux modéles, une
 variante du k-moyennes (k-means) et une variante de la carte auto-organisatrice.
\end_layout

\begin_layout Subsection
K-Means
\end_layout

\begin_layout Standard
L’algorithme de base de k-means (expliqué dans le chapitre précèdent section
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:K-means"
plural "false"
caps "false"
noprefix "false"

\end_inset

) prend en entrée une base de vecteurs de données et le nombre de clusters
 qui représente dans notre cas d’étude les comportements souhaités.
 Cependant, notre application est en temps réel, c'est-à-dire, nous aurons
 une nouvelle entrée dans chaque intervalle du temps, tout au long du flux
 vidéo.
 De plus, le modèle doit être capable de s’adapter avec les différentes
 entrées à n’importe quel instant.
 L’utilisation de l’algorithme de base pour l’application n’est pas le bon
 choix, car il nécessite un espace mémoire important due à l’extension de
 la base en temps réel, et les temps d’exécution augmentent en fonction
 de la taille de la base ce qui résulte un temps de réponse très long.
\end_layout

\begin_layout Standard
Pour pallier à ce problème, nous avons pensé en premier temps à une approche
 qui consiste à construire une base, chaque période du temps, et la passer
 à l’algorithme.
 Cette approche permet d’économiser l’espace mémoire en conservant qu’une
 petite base chaque période du temps.
 Néanmoins, on aura un nouveau modèle pour chaque base diffèrent totalement
 du modèle qui le précède car les bases d’entrées sont différentes.
\end_layout

\begin_layout Standard
Les inconvénients de l’approche précédente nous ont amené à penser à une
 deuxième approche plus performante.
 Cette dernière commence par la collection d’une base initial de taille
 n prédéfinie, ensuite, elle passe cette base à l’algorithme k-moyennes
 qui permet de produire un modèle initial.
 Par la suite, nous gardons en mémoire que les poids des prototypes des
 classes (les points centres représentant les clusters), puis, nous raffinons
 ce modèle pour chaque vecteur d’entrée.
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Subsection
Carte auto-organisatrice dynamique
\end_layout

\begin_layout Standard
Nous avons vu dans le chapitre deux, la carte organisatrice de Kohonen et
 son fonctionnent.
 Pour notre problème, nous utilisons une des variantes des cartes auto-organisat
rices bi-dimensionnelle dite la carte auto-organisatrice dynamique (en anglais
 Dynamic Self Organizing Map - DSOM) proposé par Nicolas P.
 Rougier et Yann Boniface dans 
\begin_inset CommandInset citation
LatexCommand cite
key "rougier2011dynamic"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Au contraire de l'algorithme original de la carte organisatrice qui est
 dépendante du temps (taux d'apprentissage et voisinage), celui de DSOM
 est invariant dans le temps.
 Cela permet un apprentissage en ligne et continuer sur les distributions
 de données statiques et dynamiques.
 De plus, la densité obtenue par cette variante n'est pas directement proportion
nelle à la densité de la distribution 
\begin_inset CommandInset citation
LatexCommand cite
key "rougier2011dynamic"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
La figure ci-dessus montrent la structure de la carte auto-organisatrice
 choisie pour concrétiser ce problème nous pouvons observer que les entrées
 représentent nos vecteurs caractéristiques des changements et la sortie
 est une matrice de neurones dont chacun représente un comportement bien
 défini.
 Le neurone est représenté par un vecteur des poids de taille des entrées.
 Ces poids seront modifiés par apprentissage tout au long de l'exécution.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/DSOM.svg
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Structure de la DSOM utilisée
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Au départ, nous initialisons le poids des neurones aléatoirement.
 Ensuite pour chaque vecteur caractéristique des changements en entrée,
 nous récupérons d'abord les comportements appropriés à ce dernier en prenant
 le neurone qui a la plus petite distance (le meilleur match BMU).
 Puis, nous utilisons ce vecteur d'entrée et le BMU pour ajuster les poids
 des neurones.
 Cela correspond à l'entraînement de la DSOM.
 En effet, les poids de BMU et son voisinage, determiné par la fonction
 gaussienne, seront modifiés par la formule suivante 
\begin_inset CommandInset citation
LatexCommand cite
key "rougier2011dynamic"
literal "false"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\Delta w_{i}=\varepsilon\parallel v-w_{i}\parallel h_{\eta}(i,s,v)(v-w_{i})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Avec :
\end_layout

\begin_layout Itemize
\begin_inset Argument item:1
status collapsed

\begin_layout Plain Layout
-
\end_layout

\end_inset


\begin_inset Formula $\Delta w_{i}$
\end_inset

 : le nouveau poids et 
\begin_inset Formula $w_{i}$
\end_inset

 l'ancien poids
\end_layout

\begin_layout Itemize
\begin_inset Argument item:1
status collapsed

\begin_layout Plain Layout
-
\end_layout

\end_inset


\begin_inset Formula $v$
\end_inset

 : le vecteur d'entrée
\end_layout

\begin_layout Itemize
\begin_inset Argument item:1
status collapsed

\begin_layout Plain Layout
-
\end_layout

\end_inset


\begin_inset Formula $\varepsilon$
\end_inset

 : est la constante du taux d'apprentissage (learning rate)
\end_layout

\begin_layout Itemize
\begin_inset Argument item:1
status collapsed

\begin_layout Plain Layout
-
\end_layout

\end_inset


\begin_inset Formula $h_{η}(i,s,v)$
\end_inset

 : la fonction du voisinage où
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Argument item:1
status open

\begin_layout Plain Layout
•
\end_layout

\end_inset


\begin_inset Formula $i$
\end_inset

 l'indice du neurone
\end_layout

\begin_layout Itemize
\begin_inset Argument item:1
status open

\begin_layout Plain Layout
•
\end_layout

\end_inset


\begin_inset Formula $s$
\end_inset

 représente le meilleure correspondant (BMU)
\end_layout

\begin_layout Itemize
\begin_inset Argument item:1
status open

\begin_layout Plain Layout
•
\end_layout

\end_inset


\begin_inset Formula $η$
\end_inset

 l'élasticité (un seuil pour considéré qu'un neurone et suffisament proche
 pour representer les données et donc les poids ne seront pas modifiés)
\end_layout

\end_deeper
\begin_layout Standard
Dans le cas où le neurone est suffisamment proche de la nouvelle entrée
 (distance < seuil), nous ne modifierons pas les poids car ce neurone est
 considéré comme représentant optimale du groupe dont cette donnée appartient.
 Nous répétons ces étapes tous le temps de l’exécution.
\end_layout

\begin_layout Section*
Conclusion
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{section}{Conclusion}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Nous avons présenté, dans ce chapitre, notre solution à la problématique
 posée au début de rapport.
 Nous avons obtenu de bons résultats.
 Cependant, certaines méthodes, utilisées dans les différentes étapes de
 la solution, présente des capacités assez limitées.
 Ces méthodes peuvent être subi à des amélioration et servir à améliorer
 les résultats.
\end_layout

\end_body
\end_document
